[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Web Scraping With R",
    "section": "",
    "text": "Teaching Staff\n\n\n\nProfessor Francesc Carmona.\n\n\n\n\n\nProfessor Alex Sanchez Pla"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A Website to provide materials and ressources for the Web Scraping in R course.\nPrepared using quarto and rendered from github using github pages\nhttps://aspteaching.github.io/WSWRCourse"
  },
  {
    "objectID": "RSessions.html",
    "href": "RSessions.html",
    "title": "Working with R",
    "section": "",
    "text": "Introduction to R\nData Exploration and Visualization\nData Transformations\nFunctions, loops and other automations\nDynamic reporting with Rmarkdown"
  },
  {
    "objectID": "ScrapingSessions.html",
    "href": "ScrapingSessions.html",
    "title": "Scraping sessions",
    "section": "",
    "text": "Introduction to Web Scraping (with R). (pdf)\n\nExample: Scraping the World Heritage Site (download zipped files)\n\nExample: Scraping the World Heritage Site (download zipped files)\n\n\nThe basics: HTML and CSS\n\nHTML Examples (download zipped files)\n\nHTML Examples (download zipped files)\n\n\nScraping web pages with R using rvest\n\nSelectorGadget vignette\nrvest documentation\nWeb scraping 101 (rvest vignette)\nExercises\n\nAutomation and other tools\n\nAutomating Web Scraping\nRegular expressions\n\nExercises\n\n\nParsing PDF files\n\nParsing PDF files\nExamples\n\nXML and XPath\n\nIntroduction to XML\nParsing XML with XPath\n\nExercises\n\n\nUsing APIs to get data"
  },
  {
    "objectID": "CourseIntro.html",
    "href": "CourseIntro.html",
    "title": "Course Presentation",
    "section": "",
    "text": "Objectives\nSpecifically at the end of the course students should:\nBe familiar with the main technologies to deal with information stored in the web.\nBe able to recognize the different formats that can be used for storage.\nKnow how to extract information from these formats using specific R packages\n\n\nContents\n\nIntroducing technologies. Web scrapping and web scrapping projects.\nData representation in the web HTML, XML, JSON. Other technologies.\nParsing HTML using rvest\nMore powerful parsing of HTML and XML using CSS selectors, Regular expressions and XPath.\nParsing data using APIs\nCase studies: (1) Parsing data from semi-structured documents. (2) Scraping Twitter for Sentiment Analysis. (3) Gathering data from commercial sites"
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html",
    "title": "Exercises on regular expressions",
    "section": "",
    "text": "Create a variable called text1 and populate it with the value “The current year is 2019”\nCreate a variable called my_pattern and implement the required pattern for finding any digit in the variable text1.\nUse function grepl to verify if there is a digit in the string variable."
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-2",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-2",
    "title": "Exercises on regular expressions",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nUse function gregexpr to find all the positions in text1 where there is a digit.\nPlace the results in a variable called string_position\nCan you obtain the same result using a function from the stringr package?"
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-3",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-3",
    "title": "Exercises on regular expressions",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nCreate a variable called my_pattern and implement the required pattern for finding one digit and one uppercase alphanumeric character, in variable text1. HINT: combine predefined classes in the regex pattern.\nUse function grepl or its stringr equivalent to verify if the searched pattern exists on the string."
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-4",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-4",
    "title": "Exercises on regular expressions",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nUse function regexpr or its stringr equivalent to find the position of the first space in text1.\nPlace the results in a variable called first_space and Use function grepl or its stringr equivalent to verify if the searched pattern exists on the string."
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-5",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-5",
    "title": "Exercises on regular expressions",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nCreate a pattern that checks in text1 if there is a lowercase character, followed by any character and then by a digit."
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-6",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-6",
    "title": "Exercises on regular expressions",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nFind the starting position of the above string. Place the results in a variable called string_pos2"
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-7",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-7",
    "title": "Exercises on regular expressions",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nFind the following pattern: one space followed by two lowercase letters and one more space.\nUse a function that returns the starting point of the found string and place its result in string_pos3."
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-8",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-8",
    "title": "Exercises on regular expressions",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nUsing the sub function, or its stringr equivalent, replace the pattern found on the previous exercice by the string ” is not “”\nPlace the resulting string in text2 variable."
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-9",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-9",
    "title": "Exercises on regular expressions",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nFind in text2 the following pattern: Four digits starting at the end of the string.\nUse a function that returns the starting point of the found string and place its result in string_pos4."
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-10",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-10",
    "title": "Exercises on regular expressions",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nUsing the substr function, or its stringr equivalent, and according to the position of the string found in the previous excercise, extract the first two digits found at the end of text2."
  },
  {
    "objectID": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-11",
    "href": "Exercises/ch-3-Regular expressions-Exercises.html#exercise-11",
    "title": "Exercises on regular expressions",
    "section": "Exercise 11",
    "text": "Exercise 11\n\nFile “LipidsData.csv” contains the values obtained in a metabolomics studies on lipidic concentrations in HIV patients.\nThe researchers who provided us with the data for the analysis also need to extract some information from the lipid names and give us this information.\n\nThe nomenclature is easy: We wish you to extract\n\nthe number of carbon atoms (the first number, before the two points-)\nvs. number of double bonds (the second number -after two points-) and also\nthe lipid family (last part of the name that is not a number.\n\nExample\n\nC24Cer 24 carbons; 0 double bonds, family name=“Cer”\nC24: 1Cer (a) 24 carbons; 1 double bonds, family name=“Cer”\nC24: 2Cer 24 carbons; Two double bonds, family name=“Cer”\n\n\nRead the file into R and prepare a script that parses the names and writes another file with the information desired."
  },
  {
    "objectID": "Examples/WebScraping_Course-Examples _and_Exercises.html",
    "href": "Examples/WebScraping_Course-Examples _and_Exercises.html",
    "title": "Web Scraping Course - Examples & Exercises",
    "section": "",
    "text": "library(rvest)\nlibrary(magrittr)\n\n\nTake the html_excerpt_raw variable and turn it into an HTML document that R understands using a function from the rvest package.\n\n\nhtml_excerpt_raw <- '\n<html> \n  <body> \n    <h1>Web scraping is cool</h1>\n    <p>It involves writing code – be it R or Python.</p>\n    <p><a href=\"https://datacamp.com\">DataCamp</a> \n        has courses on it.</p>\n  </body> \n</html>'\n# Turn the raw excerpt into an HTML document R understands\nhtml_excerpt <- read_html(html_excerpt_raw)\nhtml_excerpt\n\n{html_document}\n<html>\n[1] <body> \\n    <h1>Web scraping is cool</h1>\\n    <p>It involves writing co ...\n\n\n\nExtract the ol node from the list_html document, using the singular version of the rvest function that can be used to query nodes.\n\nlist_raw_html <- '<ul>\n<li>Learn HTML</li>\n<li>Learn CSS</li>\n<li>Learn R</li>\n<li>Scrape everything!*</li>\n</ul>'\n# Read in the corresponding HTML string\nlist_html <- read_html(list_raw_html)\n# Extract the ol node\nol_node <- list_html %>% \n    html_element('ol')\n\nExtract all the a nodes that are within the bulleted list, using html_elements().\n\nhyperlink_raw_html <- '<h3>Helpful links</h3>\n<ul>\n  <li><a href=\"https://wikipedia.org\">Wikipedia</a></li>\n  <li><a href=\"https://dictionary.com\">Dictionary</a></li>\n  <li><a href=\"https://duckduckgo.com\">Search Engine</a></li>\n</ul>'\n# Extract all the a nodes from the bulleted list\nlinks <- hyperlink_raw_html %>% \n  read_html() %>% \n  html_elements(\"a\")\n\nRecover the table from the page: [https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger](https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger)\n\naURL <- \"https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger\"\nmainTable <- read_html(url) # %>% \n  rvest::html_table() %>% \n  rvest::html_text2()\n\nAssume you have stored the mountains table in an html object\n\n\n| Mountain      | Height | First ascent | Country      |\n|:--------------|:-------|:-------------|:-------------|\n| Mount Everest | 8848   | 1953         | Nepal, China |\n| \\...          |        |              |              |\nTurn the table into a data frame called mountains.\n::: {.cell}\n\n```{.r .cell-code}\nmountains_html <-read_html(\"<table id='clean'>\n<tr>\n  <th>Mountain</th>\n  <th>Height</th>\n  <th>First ascent</th>\n  <th>Country</th>\n</tr>\n<tr>\n  <td>Mount Everest</td>\n  <td>8848</td>\n  <td>1953</td>\n  <td>Nepal, China</td>\n</tr>\n<tr>\n  <td>...</td>\n  </tr>\n  </table>\")\n# Extract the \"clean\" table into a data frame \nmountains <- mountains_html %>% \n  html_element(\"table#clean\") %>% \n  html_table()\n\nmountains\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  Mountain      Height `First ascent` Country     \n  <chr>          <int>          <int> <chr>       \n1 Mount Everest   8848           1953 Nepal, China\n2 ...               NA             NA <NA>        \n```\n:::\n:::\n\nRead in languages_raw_html. Select all div and p elements in this HTML\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlanguages_raw_html <- read_html('<html> \n  <body> \n    <div>Python is perfect for programming.</div>\n    <p>Still, R might be better suited for data analysis.</p>\n    <small>(And has prettier charts, too.)</small>\n  </body> \n</html>')\n# Read in the HTML\nlanguages_html <- languages_raw_html\n# Select the div and p tags and print their text\nlanguages_html %>%\n    html_elements('div p') %>%\n    html_text()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncharacter(0)\n```\n:::\n:::\n\nAn html file has been read in for you with read_html() and is available through structured_html.Using html_elements(), find the shortest possible selector to select the first div in structured_html.\n\n\n    structured_html <- read_html(\"<html>\n  <body>\n    <div id = 'first'>\n      <h1 class = 'big'>Joe Biden</h1>\n      <p class = 'first blue'>Democrat</p>\n      <p class = 'second blue'>Male</p>\n    </div>\n    <div id = 'second'>...</div>\n    <div id = 'third'>\n      <h1 class = 'big'>Donald Trump</h1>\n      <p class = 'first red'>Republican</p>\n      <p class = 'second red'>Male</p>\n    </div>\n  </body>\n</html>\")\n    # Select the first div\n    structured_html %>%\n      html_elements('#first')\n\n{xml_nodeset (1)}\n[1] <div id=\"first\">\\n      <h1 class=\"big\">Joe Biden</h1>\\n      <p class=\"f ...\n\n\n\nAn html file has been read in for you with read_html() and is available through nested_html.Select the last p node within the div.\n\n\n        nested_html<- read_html(\"<html>\n          <body>\n            <div>\n              <p class = 'text'>A sophisticated text [...]</p>\n              <p class = 'text'>Another paragraph following [...]</p>\n              <p class = 'text'>Author: T.G.</p>\n            </div>\n            <p>Copyright: DC</p>\n          </body>\n        </html>\")\n        # This time for real: Select only the last node of the p's wrapped by the div\n        nested_html  %>% \n            html_elements('p.text:last-child')\n\n{xml_nodeset (1)}\n[1] <p class=\"text\">Author: T.G.</p>\n\n\n\nHere, your goal is to scrape a list (contained in the languages_html document) of all mentioned computer languages, but without the accompanying information in the sub-bullets.\n\n\nlanguages_html <- read_html(\"<ul id = 'languages'>\n    <li>SQL</li>\n    <ul>    \n      <li>Databases</li>\n      <li>Query Language</li>\n    </ul>\n    <li>R</li>\n    <ul>\n      <li>Collection</li>\n      <li>Analysis</li>\n      <li>Visualization</li>\n    </ul>\n    <li>Python</li>\n  </ul>'\")\n\nFor that you can use the childcombinator “>”\n\n# Extract only the text of the computer languages (without the sub lists)\nlanguages_html %>% \n    html_elements('ul#languages > li') %>% \n    html_text2()\n\n[1] \"SQL\"    \"R\"      \"Python\""
  },
  {
    "objectID": "Ressources.html",
    "href": "Ressources.html",
    "title": "References and Ressources",
    "section": "",
    "text": "Courses\n\nWeb scraping in R (Datacamp)\nLearn to scrape any website with R (Udemy)\nEasy-t-follow Web Scraping (Dataslice)\n\n\n\nWeb documents/bookdown/etc\n\nWeb scraping with R by Steve Pittard\nIntroduction to Computing with Data by Gaston Sánchez\nCrime by the numbers with R, part IV is on Web Scraping.\n\n\n\nTutorials/Blog posts/etc\n\nWeb scraping for the humanities and social sciences, Rolf Fredheim and Aiora Zabala.\nR-bloggers posts on Web Scraping\nAnd see also CRAN Web Services and Technologies task view\n\n\n\nOther ressources\n\nSelectorgadget"
  }
]